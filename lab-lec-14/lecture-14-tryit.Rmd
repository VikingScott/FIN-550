---
title: "Lecture 14"
subtitle: "Bagging, random forest, and boosting"


---

# Try it: load and inspect the Boston housing dataset

```{r, message=F}
library(tidyverse)
library(ggplot2)

# Housing information for 506 areas around Boston
housing <- read_csv("lecture-14-housing.csv")
nrow(housing)
ncol(housing)

# The data are complete, so no need to remove observations
sum(!complete.cases(housing))

```

---

# Try it: build a model of housing value

```{r}

summary(housing$MEDV)

# How many predictors are available?
num.p <- 
```

---


# Try it: estimate a tree model using bagging


```{r, message=F, eval=F}
library(randomForest)
set.seed(1)

# Importance = T: calculate how important each variable is
# For bagging, number of splits m=p
bag_housing <- randomForest(MEDV ~ ., data = housing, mtry = num.p, importance = TRUE)
bag_housing

```


---

# Try it: mean-squared error for "out-of-bag" observations


```{r, eval=F}
# B (number of trees)
bag_housing$ntree

# Number of times each observation is out-of-bag (OOB)
head(bag_housing$oob.times)

# On average, what fraction of the time is an observation OOB?
```


---


# Try it: estimate a tree model using random forest

```{r, eval=F}
# Set number of random splits equal to a value less than 12
rf_housing <- randomForest(MEDV ~ ., data = housing, mtry = 6, importance = TRUE)
rf_housing

```

