---
title: "Lecture 10"
subtitle: "Cross-validation"
---

# Try it: load libraries, turn off scientific notation

```{r}
library(tidyverse)
library(ggplot2)

# scipen: a penalty for deciding whether to print fixed or exponential notation. 
# Positive values encourage fixed notation, negative encourage scientific notation
options(scipen=999)
```

------------------------------------------------------------------------

# InClass

```{r}
library(tidyverse)
set.seed(26)

flips <- tibble(
  toss = (1:10),
  heads = sample(0:1, size = 10, replace = TRUE)
)
flips
```

```{r}
fit1 = lm(heads ~ 1, data = flips)
fit2 = lm(heads ~ poly(toss,6), data = flips)

gg = flips %>%
  ggplot(aes(x = toss,y = heads))+
  geom_line(aes(y= fit1$fitted.values),color = "black")
  
gg = gg + geom_line(aes(y= fit2$fitted.values),color = "red",linewidth = 2)

gg
```

# Try it: load and inspect the Boston housing dataset

```{r, message=F}

# Housing information for 506 areas around Boston
housing <- read_csv("lecture-10-housing.csv")
nrow(housing)
ncol(housing)
```

------------------------------------------------------------------------

# Try it: validation set approach

```{r}
# Set seed for replicability (why)
set.seed(1)
n_rows <- nrow(housing)

# Randomly select half the observations
# 如果 n_rows = 100，那么 sample(n_rows, n_rows/2) 就等价于 sample(1:100, 50)。
train <- sample(n_rows, n_rows/2)

# RM degree 1
# 1. Estimate model using training observation only by specifying `subset` option
lm_1 <- lm(MEDV ~ RM, data = housing, subset = train)

# 2. Calculate MSE using test data
lm_1_mse <- mean((housing$MEDV - predict(lm_1, housing))[-train]^2)
lm_1_mse
```

------------------------------------------------------------------------

# Try it: write the function

```{r, eval=F}
f_mse <- function(order=10, seed=NULL) {
  mse_lm <- rep(0,order) 
  set.seed(seed)
  n_rows <- nrow(housing)
  train <- sample(n_rows, n_rows/2)
  
  for (j in 1:order){
    # Estimate training model where Y = MEDV and X = polynomial in rooms of order j
    lm <- lm(MEDV ~ poly(RM, degree = j, raw = TRUE),
                     data = housing[train, ])
    
    # Calculate the MSE using test data (hint: look at code on previous slide)
    y_hat <- predict(lm, newdata = housing[-train, ])
    y_true <- housing$MEDV[-train]
    mse_lm[j] <- mean((y_true - y_hat)^2, na.rm = TRUE)
  }
  
  return(mse_lm)  
}

```

------------------------------------------------------------------------

# Try it: call the function using different seeds

```{r, eval=F}
# Confirm that we get the same results as previous slide (RM degree 1, 2, 3)
f_mse(1,1)
f_mse(2,1)
f_mse(3,1)

mse_1 <- f_mse(10, 891)
mse_2 <- f_mse(10, 892)
mse_3 <- f_mse(10, 893)
mse_4 <- f_mse(10, 894)
mse_5 <- f_mse(10, 895)

# Build a data frame with the results
mse <- data.frame(mse_1, mse_2, mse_3, mse_4, mse_5) %>% 
  mutate(order = row_number())
```

------------------------------------------------------------------------

# Try it: plot our results

```{r b7, results=F, fig.show="hide", eval=F}

# Show MSE as a function of the polynomial degree
#   for the 5 different seeds we tried
ggplot(mse, aes(x=order)) + theme_bw() +
  geom_line(aes(y = mse_1), color = "red") + 
  geom_line(aes(y = mse_2), color = "blue") + 
  geom_line(aes(y = mse_3), color = "green") + 
  geom_line(aes(y = mse_4), color = "orange") + 
  geom_line(aes(y = mse_5), color = "black") +
  scale_x_continuous(breaks = c(1:10)) +
  theme(
    axis.title = element_text(size = 26),
    axis.text = element_text(size = 20),
    panel.grid.major.x = element_blank(),
    panel.grid.minor.x = element_blank()
  )
```

------------------------------------------------------------------------
