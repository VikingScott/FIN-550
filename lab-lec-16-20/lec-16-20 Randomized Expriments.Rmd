---
title: "lec-18 Randomized Experiments"
output: html_document
date: "2025-11-10"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Causual Material

## Design a causal analysis

-   outcome: the target for the study
-   treatment: a variable that measures the causual relation of interest
-   treatment group & control group

Goal: Use randomized experiment design to avoid selection bias (known as
"A/B Test")

我们想估计一个参数（estimand），用一个统计方法（estimator）计算得到一个估计值（estimate）。但因为数据是随机抽样的，所以不同的样本会产生不同的
estimate，这就是 sampling error，也会导致不确定性。

## CLT中心极限定律

当你从某个总体中随机抽取很多样本，并计算这些样本的平均值，那么：

无论原始数据的分布长什么样（偏的、长尾的、不对称的、非正态的都可以），只要样本量足够大，样本平均值的分布都会变成正态分布。

换句话说：

原始数据不需要是正态的，但样本均值会变得接近正态。

例子：
一个人每天的消费金额分布不对称、尾巴很长，但是如果你每天取几十个顾客的平均消费，再重复很多次这种“取平均”的过程，这些平均值就会形成近似的正态分布。

中心极限定理的意义：
它告诉你：为什么在现实中我们可以使用正态分布来做推断，即使数据不是正态。
它解释了为什么 t
检验、回归中的误差项、置信区间这些统计工具都能正常工作。
它允许我们用正态近似来计算置信区间、标准误、p 值。

### 实证分析
首先我们来看看标普指数

```{r, warning=FALSE}
library(quantmod)
library(dplyr)
library(tidyr)

start_date <- as.Date("2000-01-01")
end_date   <- Sys.Date() - 1

# 1) 拉 SPY
spy_xts <- getSymbols("SPY",
                      src = "yahoo",
                      from = start_date,
                      to   = end_date,
                      auto.assign = FALSE)

# 2) Adj Close
px <- Ad(spy_xts)
colnames(px) <- "adj_close"

# 3) 两种收益率（注意：通常从第2天开始，所以长度 N-1）
ret_simple <- dailyReturn(px, type = "arithmetic")
colnames(ret_simple) <- "simple"

ret_log <- dailyReturn(px, type = "log")
colnames(ret_log) <- "log"

# 4) 对齐合并（只保留共有日期）
m <- merge(px, ret_simple, ret_log, join = "inner")
m <- na.omit(m)  # 防止有任何 NA

# 5) 转成 data.frame
spy_df <- data.frame(
  date      = as.Date(index(m)),
  adj_close = as.numeric(m$adj_close),
  simple    = as.numeric(m$simple),
  log       = as.numeric(m$log)
) %>% arrange(date)

# 6) 检查
cat("Requested end date:", as.character(end_date), "\n")
cat("Last date in data  :", as.character(max(spy_df$date)), "\n")
cat("Rows:", nrow(spy_df), "\n\n")

head(spy_df)
tail(spy_df)

# spy_xts 是你 getSymbols 得到的 xts
tail(index(spy_xts), 10)          # 看最后10个交易日日期
spy_xts["2025-12-12"]             # 直接取 12/12 那天（有就会显示一行）
```

### Law of Large Numbers 大数定律

样本平均值是一个 consistent
estimator（一致的估计量），所以样本越大，样本平均值就越接近总体平均值。

LLN 分为弱大数定律（WLLN）和强大数定律（SLLN）： 弱大数定律：X̄\_N
以概率收敛到 μ 强大数定律：X̄\_N 几乎处处收敛到 μ（更强）

直觉但不平凡的数学点：
直觉上你会觉得平均值应该趋向于真实值，但数学上这不是显然的，需要严格证明。
它依赖独立性、期望存在，以及一些技术条件（如 Kolmogorov 条件）。
有些奇怪的分布甚至会破坏 LLN（例如某些具有无限方差的分布）。

任何估计量的一致性都依赖 LLN。
例如样本均值估计总体均值、一致估计的定义、最大似然估计的一致性、OLS
系数收敛到真实系数，这些全部基于 LLN。 没有
LLN，“用样本推总体”这件事根本没有数学保证，统计学就崩溃了。

### Precision

#### Standard Error

定义： 标准误就是“估计量的标准差”，也就是：

SE(β̂) = sqrt( Var(β̂) )

含义： 如果你重复抽样很多次，每次得到一个新的 β̂，那么这些 β̂
的散布程度就是 SE。

直觉理解： SE 越小 → 估计越稳定（波动少）。 SE 越大 →
估计越不稳定（噪音多）。

与样本大小的关系： 一般情况下 SE ≈ σ / sqrt(N) 因此：样本越大 →
精确度越高 → SE 越小。

#### Confidence Interval（置信区间）

定义： 根据估计值和标准误构造一个范围，这个范围“很可能”包含真实参数。

95% 置信区间公式（大样本近似）：

estimate ± 2 × standard error

含义： 如果你重复抽样 100 次，构造 100 个 95% CI，那么大约 95
个区间会覆盖真实参数。

重要点： 置信区间不是说“95% 的概率真实值在区间里”。 真实值是固定的。
概率来自“区间是随机的”。

简单理解： CI = 估计值 ± 不确定性 不确定性由 SE 决定。

#### p-value（p 值）

定义： 在假设真实参数为 0 的前提下，
你观察到的估计值（或更极端的结果）出现的概率。

换句话说： p-value = 在“假设没有效果”的世界里，这种估计值有多罕见？

含义： p 值小 → 这种估计值在“无效果模型”中很难出现 → 不太像零 p 值大 →
这种估计值在“无效果模型”中很常见 → 可能就是零

一个常见判别： p \< 0.05 → 拒绝“β = 0”的假设（统计显著）
但这只是惯例，不是绝对真理。

### 为什么要randomize

在因果推断中，我们真正想要衡量的，是同一批人在“接受处理”与“未接受处理”这两种情况下结果的差异，也就是反事实因果效应
A − C

A = 治疗组在“有治疗”下的结果（想得到、也能看到）

例如： 有保险的人实际的健康水平

C = 治疗组在“无治疗”下的结果（想得到、但不能看到）

例如： 有保险这一批人，如果他们没保险，会有怎样的健康？
这是“反事实”，不可观测。

B = 对照组在“无治疗”下的结果（能看到）

例如： 没有保险的人实际的健康水平

然而 C
永远无法被直接观测，因此实际研究中人们常用处理组（有处理）的真实结果A，减去对照组（无处理）的真实结果
B 来估计因果效应，即 A − B。
但这里的关键问题是：对照组并不能代表“处理组如果没有接受处理时会是什么样子”，换言之
B 不能代替 C。这意味着 A − B 不仅包含我们想要的因果效应（A −
C），还包含处理组与对照组在未接受处理时本来就存在的固有差异（C −
B），这部分差异就是“选择偏差”。 因此，观察到的组均值差可以写成：A − B =
(A − C) + (C − B)，其中第一项是因果效应，第二项是选择偏差。

选择偏差的来源是：在现实世界中，是否接受处理往往取决于个人特征——例如，购买健康保险的人可能本来就更富裕、更健康、更受教育，这使得
C 通常高于
B，从而带来偏差。只有在随机化设计中，处理的分配与个体特征无关，使得 C ≈
B，也就是说处理组与对照组在未接受处理时的反事实状态等同。这时选择偏差消失，A
− B
才能准确估计因果效应。因此，随机化实验之所以被视为识别因果关系的“金标准”，就在于它直接解决了对照组无法代表反事实的问题。

## Limitation

### Randomization failure

概念： 随机分组没有成功，两组在试验开始前本来就不同 →
组间差异无法解释为因果效应。

例子：
在健康保险试验中，如果随机化不完全，有更多富裕人群被分到“保险组”，而贫困人群被分到“无保险组”，那么两组收入、教育、健康等差异本来就存在。此时即使看到“保险组更健康”，也可能只是因为这批人本来就健康，而不是保险带来的效应。

关键影响： → 导致选择偏差（selection bias） →
因果效应被污染，实验结果不可信

### Attrition bias（流失偏差、掉队偏差）

概念： 实验中有些人退出，而退出的模式与处理分配有关。
如果不同组退出的类型不同，会破坏随机化。

例子：
在健身计划实验中，处理组（上健身课）里坚持不下去的人更容易退出，而对照组（不上课）的人退出较少。
结果是： • 处理组只剩下一群更有毅力、身体更好的人 • 对照组仍包括所有人

这样比较两组就会错误地认为健身课特别有效。

关键影响： → 剩下的人已不再随机 →
因果估计向好的一方或坏的一方偏移（偏误方向难以预测）

### External validity（外部有效性/可推广性问题）

概念：
实验结果只能适用于实验样本，而不能推广到更大的真实人群或不同情境。

例子： 某教育实验在麻省理工学生中测试“用 AI
辅助写作提高论文质量”，结果显著提升。然而这个结果未必适用于： •
中国高中生 • 法学院学生 • 不同国家文化背景 • 不同 AI 水平

实验样本通常过于“特定”，导致结果不能外推到其他群体。

关键影响： → 研究有效但无法推广 → 政策应用需要谨慎

### Statistical power（统计功效不足）

概念： 样本太小，标准误太大 → 实验无法检测到真实存在的效应（假阴性）。

例子： 你做一个“维他命 D 是否改善情绪”的实验，每组只有 20 个人。
即使维他命 D 真的有效，小样本也可能使 95% CI 太宽 →
差异不显著，被误以为“无效”。

关键影响： → 有效的干预也可能被错判为无效 → 样本不足是 RCT
的最大实际限制之一（成本贵）

## Example

它模拟了一个经典的随机实验（RCT）场景：

• 每个人有一个年龄

• 每个人被随机分到 treatment（1 或 0）

• 因变量 spending 由：

• 截距

• 处理效应（因果效应）

• 年龄效应

• 随机误差

构成

实际上，这生成的数据背后隐含一个“真实模型”：

$spending_i = \beta_0 + \beta_1 \cdot treat_i + \beta_2 \cdot age_i + \varepsilon_i$

这就是 econometrics（计量经济学）中的经典线性回归模型。

```{r}
library(tidyverse)
library(ggplot2)
library(broom)

# Function to create dataset with N observations
data_sample <- function(
  N = 100,
  beta0 = 10,
  beta1 = 1,
  beta2 = 0.1,
  sd_e = 3
) {
  
  data <- tibble(
    age = sample(seq(18, 100), N, replace = TRUE),
    treat = sample(c(0, 1), N, replace = TRUE),
    spending = beta0 +
               beta1 * treat +
               beta2 * age +
               rnorm(N, mean = 0, sd = sd_e)
  )
  
  # Move spending to be the first column
  data <- data %>% relocate(spending, .before = age)
  
  return(data)
}

set.seed(10)
df <- data_sample(N=100)
cat("\n")
head(df)

df %>%
  group_by(treat) %>%
  summarize(mean_age = mean(age))
```

### Balance test on example

```{r}
lm1 = lm(age ~ treat, data = df)
tidy(lm1, conf.int =T, conf.level =0.95)
```

treatment 组平均年龄 ≈ control 组 + 3.4 岁

treat的p大于 0.05 → 不显著

说明：

➡ 两组年龄差异不显著

➡ 随机分组成功（至少在年龄这个维度）

### Causual Treatment Effect

1.计算两组均值差

```{r}
mean(df$spending[df$treat==1]) - mean(df$spending[df$treat==0])
```

treat 组平均 spending 比 control 组高 1.49。这是你对 平均处理效应（ATE）
的朴素估计。

2.然后你用回归来检验这个差异是否显著

```{r}
lm2 <- lm(spending ~ treat, data = df)
tidy(lm2, conf.int = TRUE)
```

$spending_i = \beta_0 + \beta_1 \cdot treat_i + \epsilon_i$

其中：

• β₀ = control 组的平均 spending

• β₁ = treatment effect = 两组均值差

treat = 1.49,p = 0.0796 \> 0.05

说明： ✔ 弱显著（10% 水平显著） ✘ 不显著（5% 水平）

也就是说：

👉 你看到 treatment 可能提高 spending

👉 但证据不够强，不能 95% 置信地说它“必然”有影响

**Treatment 组比 Control 组平均多花 1.49，但这个差异在 5%
显著性水平下并不显著（CI 跨过 0）。**

但是，模型中 treatment effect = 1，是真实存在的。但样本量只有
100，加上噪音较大，所以统计上不显著。显著性不足来源于 sample
size，而不是模型问题。

#iThrive Wellness Program

研究团队在 UIUC
做了一个为期两年的随机对照实验，想评估一个设计得非常完善、带金钱激励的职场健康项目
iThrive 是否能改善员工健康行为和健康结果。他们先向全校 12,459
名员工发出调查邀请，最终有 4,834
人完成基线问卷，这些人被用作实验样本，再通过个体随机分配成 3,300 人的
treatment 组和 1,534 人的 control 组。Treatment
组可以参加包含体检、健康风险评估和多种健康课程的 iThrive
项目，并获得最高每年几百美元的激励以及带薪参加时间；control
组则不享受这些安排。研究者把问卷、生物体征、健身使用记录和医疗理赔等多种数据链接起来，对两组在两年内的健康行为、健康水平和医疗支出进行比较，从而估计
iThrive 的因果效应，并讨论它对现实中工作场所健康计划的政策意义。

在 Illinois Workplace Wellness Study 里，虽然员工被随机分配到 treatment
/ control 组，但在 treatment 组内部，真正参加 iThrive
的人原本就更健康、医疗花费更低、健康行为更好，因此简单比较“参加者 vs
不参加者”的差异会严重高估项目效果；要识别因果效应，应以随机分配的 treat
vs control（ITT）为基础，而不是以自愿参加与否来做比较。

Result 2 用的基本方法是：把每个结局变量
$Y_i$（比如有没有体检、月医疗支出、健身房次数、是否晋升等）拿出来，对
4,834 个被随机分到 treatment / control 的员工做一个简单回归
$Y_i = \beta_0 + \beta_1 T_i + \varepsilon_i$, 其中 $T_i=1$ 表示被分到
iThrive 计划的处理组，$T_i=0$
是对照组。因为分组是随机的，组间在基线特征上已经很接近，所以 $\beta_1$
就可以直接被解释为“参加健康计划邀请”对这个结局的平均因果效应（Intent-to-Treat，ITT）。在实际计算上，这个回归和“处理组平均值减去对照组平均值”是等价的，只是回归能顺便给出标准误、p
值和 95% 置信区间，方便判断差异是不是统计显著。

先看他们最“显著”的一个正面结果：是否“从未参加过任何健康筛查”。12
个月时，对照组大约有 8.5% 的人从没做过筛查，处理组只有 4.5%；24
个月时，对照组 5.8%，处理组
2.9%。两张图里橙色柱子明显比蓝色柱子矮很多，而且橙色柱子的 95%
置信区间和蓝色的几乎不重叠，这意味着 $\beta_1$ 显著小于
0（差不只是随机波动）。用回归语言说，就是“被邀请参加
iThrive”显著降低了完全不体检的比例，大概减少了 3–4
个百分点，所以在“让更多人去做一次筛查”这件事上，项目是有效果的。

但是，当他们把目光转到更“硬核”的结局上时（医疗支出、长期健康行为、生产率），结果几乎都是“没有显著因果效应”。医疗支出那张图把
30 个月后的月支出分成若干区间：0、美金
0–92、92–275、275–620、620–1409、1409–2697、2697+，每个区间里 treatment
和 control 的比例都非常接近，两边的 95%
置信区间高度重叠，旁边还给出了卡方检验和 KS 检验的 p 值（0.176 和
0.373），都远大于
0.05，说明治疗组和对照组的支出分布在统计上无法区分，也就是看不到“项目显著降低医疗支出”的证据。健身房年访问次数、跑步活动参加率、晋升概率、病假天数这些指标也是类似：蓝色和橙色柱子高度差很小，误差棒大幅重叠，对应的
$\beta_1$ 接近 0 且不显著，所以结论是“30
个月后，项目对健康行为和工作生产率没有显著的平均因果影响”。

最后一张“我们排除了 84%
既有研究的估计”是在回答一个担心：会不会我们的估计只是太
noisy，看不到效果而已？他们把自己的估计（橙色星星）和前人文献里关于医疗支出、缺勤减少的百分比变化一一放在同一张图上，再画出自己估计的
95% 置信区间（红色括号）。可以看到，他们的点估计非常靠近
0，而且置信区间相对比较窄，已经把很多文献中报告的“医疗支出降低
20%、缺勤减少 30%”这类巨大效果排除在区间之外——这就是“rule out 84% of
prior
estimates”的意思。换句话说，他们的“无显著效果”不是因为样本太小、噪声太大，而是说明：在这个大样本、严谨随机设计下，工作场所健康计划最多只能产生非常有限的经济和生产率收益，而不太可能像一些早期研究声称的那样带来特别巨大的成本节约。
