---
title: "Lab-06: Machine Learning, Bias, and Variance"
author: Yongpeng Fu
output:
  html_document:
  theme: simplex
  fig_caption: true
---

# Getting started

In this exercise you will create a simulation in which you understand how the (simulated) world works. Using data that are generated by this world, you will use machine learning (ML) to try to reverse engineer how the world works. You will calculate the mean squared error (MSE) of different ML algorithms and decompose the MSE into noise, bias, and variance components.

Start by loading the `tidyverse` package.

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
```

# Simulation Setup

We will build a world in which outcomes $Y$ are related to a predictor variable $X$ according to the equation $Y = f(X) + \epsilon,$ where $\epsilon$ is a mean-zero normally distributed random variable and

$$ f(X) = -16 + 24X - 9X^2 + X^3. $$ Remember that $f$ is the conditional expectation function, describing the expected value of $Y$ given $X$. The following code chunk defines and plots this function for values of $X$ ranging from 0 to 6.

```{r}
# Define f, the conditional expectation function (ground truth)
f <- function(x) -16 + 24*x - 9*x^2 + x^3
ggplot() +
  geom_function(fun = f, xlim = c(0, 6), color = "orange", linewidth = 1.5)
```

We need our world to generate data. In some cases, we'll want to collect data where the world picks values of $X$ along with corresponding values of $Y$. In other cases, we might want to collect data for specific values of $X$, and let the world generate only the corresponding $Y$ values.

The function in the following code chunk can perform either task. The function always returns a data frame that contains the following variables:

-   `x` -- The value of the predictor variable $X$ for each observation in the dataset
-   `f` -- The true expected value of $Y$ given $X$ (we can only calculate this in a simulation, where we are omnicient)
-   `epsilon` -- The noise term $\epsilon$ that causes realized outcomes to deviate from their expected values
-   `y` -- The realized outcome, defined by $y = f(x) + \epsilon$

The function has two modes:

1.  If you set the `at` argument equal to `NULL` and provide a positive value for `n`, the function will create a sample of `n` observations, and for each observation will randomly select a characteristic `x` in the interval 0 to 6.
2.  If you set the `at` argument to be a vector of `x` characteristics, the function will create a sample of `n = length(x)` observations with characteristics defined by `x = at`.

Finally, you get to determine how much noise there is in this world via the `sd` argument, which sets the standard deviation used when randomly drawing values for the error term `epsilon`. For example, if you set `sd = 0`, there will be no noise, and outcomes will be perfectly determined given `x`. By contrast, when `sd` is large, outcomes will be only partly detmined by `x`.

```{r}
# Define draw, a function that draws a data sample
#   at    A vector of predictors x. If NULL (the default), predictors are drawn randomly between 0 and 6
#   sd    The standard deviation of epsilon
draw <- function(at = NULL, n, sd, fun = f) {
  if (is.null(at)) at <- runif(n = n, min = 0, max = 6) 
  tibble(x = at,
         f = f(x),
         epsilon = rnorm(n = length(x), mean = 0, sd = sd),
         y = f(x) + epsilon)
}
```

# Problem 1: Draw data samples

This problem helps you gain familiarity with how to draw data samples in the simulation using the `draw` function.

First, collect a data sample of `n = 5` observations, where the characteristics `x` are selected randomly from the interval 0 to 6 (i.e., using mode 1 described above). Set the standard deviation of `epsilon` equal to zero. Print the contents of this data frame.

```{r}
# `draw` mode 1: draw a sample of 5 observations, using random values of x
draw(n = 5, sd = 0)

```

Next, collect a data sample where the characteristics `x` are the sequence of values from 0 to 6 in increments of 0.5. Set the standard deviation of `epsilon` equal to 10. Print the contents of this data frame.

```{r}
# `draw` mode 2: draw a sample where the predictors are fixed at values from 0 to 6 in increments of 0.5
draw(at = seq(0,6,by = 0.5),
     sd = 10)

```

# Problem 2: Visualizing noise

In this problem, use the `draw` function along with `ggplot2` to visualize how noise obscures $f$, the systematic relationship between $X$ and $Y$.

### No noise

In the following code chunk, collect a data sample where the characteristics `x` are the sequence of values from 0 to 6 in increments of 0.5. Set the standard deviation of `epsilon` equal to zero. Create a single ggplot that has the following two layers:

1.  First layer. A line plot of how `f` (the true expected value of `y` given `x`) varies with `x`. Set the line color to be orange, and the line width to be 1.5.
2.  Second layer. A scatter plot of how `y` (the realized outcome) varies with `x`. Set the point color to be black, and the line width to be 3.

```{r}
# Plot f and y with a data sample of size 13, no noise (sd = 0)
D = draw(at = seq(0,6,by = .5), sd = 0)
ggplot() +
  geom_function(fun = f, xlim = c(0, 6), color = "orange", linewidth = 1.5) +
  geom_point(data = D,aes(x = x,y = y),color = "black",size = 3 )
```

### More noise

Repeat the exercise from the "no noise" scenario, except now set the standard deviation of `epsilon` to be equal to 10.

```{r}
# Plot f and y with a data sample of size 13, more noise (sd = 10)
D = draw(at = seq(0,6,by = .5), sd = 10)

ggplot() +
  geom_function(fun = f, xlim = c(0, 6), color = "orange", linewidth = 1.5) +
  geom_point(data = D,aes(x = x,y = y),color = "black",size = 3 )

```

### Discuss

In which world do you expect machine learning to perform better? How would your conclusions change, if at all, if you collected data samples where the characteristics `x` were selected randomly instead of at fixed intervals? Discuss briefly, connecting your discussion to the patterns revealed in your plots.

In a noise free world, then ML will perform the best. Changing training x from fixed to random doesn’t change the fundamental bias–variance–noise tradeoff, but it changes the *distribution of variance* across x. Random x leads to uneven variance patterns, while fixed grid x gives smoother, more predictable behavior.

# 

Problem 3: The Machine

### Setup

In this problem, we will use machine learning to construct an estimate of $f$, based only on values of `x` and `y` observed in data samples generated by this world. The machine learning algorithm will employ linear regression. Despite its name, linear regression can be used to estimate many types of nonlinear relationships, including polynomial relationships.

We will use the following R functions to estimate $f$ using linear regression and to make predictions. You can look up the help documentation for each to learn more.

-   `lm` -- Fits linear models
-   `poly` -- Constructs polynomials of a specified degree
    -   Example 1: `y ~ poly(x, degree = 1, raw = TRUE)` builds a simple linear model of the form $y = \beta_0 + \beta_1 x + \epsilon$
    -   Example 2: `y ~ poly(x, degree = 3, raw = TRUE)` builds a cubic model of the form $y = \beta_0 + \beta_1 x + \beta_2 x^2 + \beta_3 x^3 + \epsilon$
-   `predict.lm` -- Uses the output of `lm` to predict the outcome for specified values of `x`

Our machine learning algorithm has three different arguments:

1.  `test_data` -- The dataset, produced by `draw`, for which we want to predict the outcomes.
2.  `training_data` -- The dataset, produced by `draw`, that will we use to estimate $f$ via linear regression.
3.  `deg` -- Specifies the degree of the polynomial in $x$ for the estimate of `f`.

The function `f_hat` implements this algorithm. Given the needed inputs, the function returns a data frame equal to `test_data`, but with an additional column `y_hat` of the predicted outcomes.

```{r}
# Define f_hat, the machine learning algorithm. 
# Output
#   A data frame consisting of x from test_data and the corresponding predictions y_hat = f_hat(x)
f_hat <- function(test_data, training_data, deg) {
  y_hat <- lm(y ~ poly(x, degree = deg, raw = TRUE), data = training_data) %>% 
    predict.lm(newdata = test_data)
  mutate(test_data, y_hat = y_hat)
}
```

### ML under no noise

Run the ML algorithm under a scenario where the world is deterministic (no noise). To do so, implement the algorithm with the following inputs:

-   `test_data` -- Collect a data sample where the characteristics `x` are the sequence of values from 0 to 6 in increments of 0.5 and the standard deviation of `epsilon` equal to zero.
-   `training_data` -- Collect a data sample of `n = 10` observations, where the characteristics `x` are selected randomly and the standard deviation of `epsilon` equal to zero.
-   `deg` -- Set `f_hat` to be a cubic function of `x` (`deg = 3`).

Using the result generated by `f_hat`, create a single ggplot that has the following three layers:

1.  First layer. A line plot of how `f` varies with `x`. Set the line color to be orange, and line width to be 1.5.
2.  Second layer. A line plot of how `y_hat` varies with `x`. Set the point color to be blue, line width to be 3, and transparency to be 1/2.
3.  Third layer. A scatter plot of how `y` varies with `x`. Set the point color to be black, and line width to be 3.

```{r}
# Plot f with a training data and test data predictions
result = f_hat(
  test_data = draw(at = seq(0,6,by = 0.5),sd = 0),
  training_data = draw(n = 10, sd = 0),
  deg = 3
)
ggplot() +
  geom_function(fun = f, xlim = c(0,6),
                color = "orange", linewidth = 1.5) +
  geom_line(data = result, aes(x = x, y = y_hat),
            color = "blue", linewidth = 3, alpha = 0.5) +
  geom_point(data = draw(n = 10, sd = 0), aes(x = x, y = y),
             color = "black", size = 3)

```

**Discuss:** How well did the prediction algorithm perform? Is there any bias or variance in this case? Would that change if you had forced `f_hat` estimate a simple linear function of `x` (i.e., set `deg = 1`)?

It was a perfect match in the prediction. If we use deg = 1, it will be a lot of bias as it oversimplified the model.

### ML under noise

Repeat the exercise of "ML under no noise," except this time add noise to the world by setting the standard deviation of $\epsilon$ to be equal to 10 when drawing the `test_data` and `training_data`. How do the results and your discussion points change?

```{r}
# Plot f with a training data and test data predictions
set.seed(111)
test_data = draw(at = seq(0,6,by = 0.5),sd = 10)
training_data = draw(n = 10, sd = 10)
result = f_hat(
  test_data = test_data,
  training_data = training_data,
  deg = 3
)
ggplot() +
  geom_function(fun = f, xlim = c(0,6),
                color = "orange", linewidth = 1.5) +
  geom_line(data = result, aes(x = x, y = y_hat),
            color = "blue", linewidth = 3, alpha = 0.5) +
  geom_point(data = training_data, aes(x = x, y = y),
             color = "black", size = 3)

```

We observe some variance and bias, the line diverges from the true distribution.

# Problem 4: MSE

As a final step, you will calculate MSE from the machine learning algorithm. To do so, repeat the prediction part (not the visualization part) of the previous exercise "ML under noise" many times (i.e., `deg = 3`, `sd = 10`, etc.). Collect the prediction results as you go. Finally, using this collection of results, calculate how well the ML algorithm performed on average.

### Repeat the ML algorithm many times

In the following code chunk, use a `for` loop to repeat the prediction exercise 1,000 times. Save the output from the $i^\textit{th}$ iteration of the loop in the $i^\textit{th}$ position of the list `f_hat_list`. In the end, each element of this list will be the data frame returned by `f_hat`.

```{r}
# How many iterations (start with 2 iterations, then increase to 1,000 once the code is working)
iters <- 1000
deg = 3
sd = 10
test_data = draw(at = seq(0, 6, by = 0.5), sd = 10, fun = f)

# Create an empty list to store the output from each iteration of the for loop
f_hat_list <- vector("list", iters)
for (i in 1:iters) {
  training_data = draw(n = 10, sd = sd, fun = f)  
  f_hat_list[[i]] = f_hat(test_data, training_data, deg)
}

head(f_hat_list[[1]])
```

### Assess the quality of predictions

Now that you have the results of estimating the ML algorithm many times, create a data frame called `f_hat_sum` that summarizes prediction results, separately for each value of `x` in `test_data`. (Hints: combine the list of data frames into one long data frame using `bind_rows`, then use `group_by` and `summarise` as appropriate to create the requested summaries.)

The summary data frame should contain one row for each value of `x` in `test_data` and should contain the following variables:

-   `y_hat_mean` -- The mean predicted outcome
-   `f_mean` -- The mean of the `f` (the true expected value, for use as a benchmark)
-   `mse` -- The mean squared error of predictions
-   `noise` -- The mean of `epsilon` squared
-   `bias_squared` -- The bias in the predictions, squared
-   `variance` -- The variance in the predictions

Add code to the following code chunk to build this summary data set, and then print the contents.

```{r}
all_pred <- dplyr::bind_rows(f_hat_list, .id = "iter")
f_hat_sum = all_pred %>%
  group_by(x) %>%
  summarise(
  y_hat_mean = mean(y_hat),
  f_mean = mean(f),
  mse = mean((y - y_hat)^2),
  noise = mean((y - f)^2),
  bias_squared = (f_mean - y_hat_mean)^2,
  variance = var(y_hat)
  )
f_hat_sum %>%
  mutate(check = noise + bias_squared + variance) %>%
  select(x,y_hat_mean,f_mean,noise,bias_squared,variance,check,mse)
  
```

Using the results, briefly discuss the following:

-   Is it true that MSE = Noise + Bias\^2 + Variance?
    -   Very close
-   Is MSE the same at all values of `x`? How is this related to the discussion question at the end of Problem 2?
    -   MSE is not the same around all x, it proves our point before: With random training x, variance (and thus MSE) is uneven across the domain, while with fixed evenly spaced x, the MSE pattern would be smoother.
-   What component (noise, bias, or variance) is driving most of the MSE? Does it depend on the value of `x`?
    -   Variance is the main driver, bias is the least. Variance is the greatest at the edge of the domain and smaller in the middle

### Visualize

Visualize the summary of prediction results. Using the summary data frame you just constructed, create a ggplot with the following two layers:

1.  First layer. A line plot of how `f_mean` (which is the same as `f`) varies with `x`. Set the line color to be orange, and the line width to be 1.5.
2.  Second layer. A line plot of how `y_hat_mean` varies with `x`. Set the point color to be blue, size to be 3, and transparency to be 1/2.

Discuss: What does this plot indicate about bias in the ML algorithm? What about variance?

```{r}

ggplot(f_hat_sum, aes(x = x)) +
  
  geom_line(aes(y = f_mean), 
            color = "orange", linewidth = 1.5) +
  
  geom_point(aes(y = y_hat_mean), 
             color = "blue", size = 3, alpha = 0.5) +
  
  labs(x = "x", y = "Value",
       title = "True Function vs Mean Prediction")
  
```

This plot shows that the ML algorithm has **very low bias**, since the mean predictions closely follow the true function. This success comes from choosing the correct model complexity: we set deg = 3, which matches the true cubic form of f(x), so the algorithm is unbiased on average. However, earlier decomposition results showed that **variance dominates the MSE**, especially at the boundaries of the domain. Thus, while bias is negligible due to the correct choice of polynomial degree, the algorithm’s errors are mainly driven by variance.

# Problem 5 [optional]: Bias-Variance Tradeoff

On average, over values of $X$ from 0 to 6, and under the "ML under noise" (`sd` = 10) scenario, do you get a larger or smaller MSE when the ML algorithm estimates $f$ as a cubic function of $X$ (`deg = 3`, as done in Problem 4) or as a simple linear function of $X$ (`deg = 1`)? Which version of the algorithm leads to higher bias, and which to higher variance?

Discuss these findings and evaluate the following claim: if the true `f` is nonlinear, then a simple linear models will generally perform worse than a nonlinear model.

```{r message=FALSE, warning=FALSE}
library(tidyverse)
run_experiment <- function(deg, iters = 1000, sd = 10, n_train = 10) {
  test_data = draw(at = seq(0, 6, by = 0.5), sd = 0, fun = f)
  
  f_hat_list = vector("list", iters)
  for (i in 1:iters) {
    training_data = draw(n = n_train, sd = sd, fun = f)
    f_hat_list[[i]] = f_hat(test_data, training_data, deg)
  }
  all_pred = dplyr::bind_rows(f_hat_list, .id = "iter")
  
  summary = all_pred %>%
    group_by(x) %>%
    summarise(
      f_mean = mean(f),
      y_hat_mean = mean(y_hat),
      mse = mean((y - y_hat)^2),
      noise = mean((y - f)^2),
      bias_sq = (mean(f) - mean(y_hat))^2,
      variance = var(y_hat),
    )

  summary %>%
    summarise(
      avg_mse = mean(mse),
      avg_noise = mean(noise),
      avg_bias_sq = mean(bias_sq),
      avg_var = mean(variance)
    ) %>%
    mutate(deg = deg)
}

# run for cubic (deg=3) and linear (deg=1)
results = bind_rows(
  run_experiment(deg = 3, iters = 1000, sd = 10),
  run_experiment(deg = 1, iters = 1000, sd = 10)
)

results
```

The cubic model has almost no bias but extremely high variance, leading to a much larger MSE than the linear model. The linear model, while biased, is more stable and achieves lower overall error under noisy, small-sample conditions. This means the claim that “linear models will generally perform worse when the true function is nonlinear” is not always true — it depends on the balance between bias and variance. With more data or lower noise, the nonlinear model would likely outperform, but in this setting, the simple linear model actually does better.
